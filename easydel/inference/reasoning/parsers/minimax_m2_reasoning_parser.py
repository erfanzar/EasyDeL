# Copyright 2025 The EasyDeL Author @erfanzar (Erfan Zare Chavoshi).
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     https://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Reasoning parsers for MiniMax M2 models.

MiniMax M2 has asymmetric token handling:
- MiniMaxM2ReasoningParser: Treats all content before </think> as reasoning
  (no explicit start token generated by the model).
- MiniMaxM2AppendThinkReasoningParser: Synthetically prepends <think> to output.
"""

from __future__ import annotations

from collections.abc import Sequence

from ...openai_api_modules import DeltaMessage
from ..abstract_reasoning import ReasoningParserManager
from ..basic_parsers import BaseThinkingReasoningParser


@ReasoningParserManager.register_module(["minimax_m2"])
class MiniMaxM2ReasoningParser(BaseThinkingReasoningParser):
    """Asymmetric reasoning parser: no start token, only </think> end token.

    Treats everything before </think> as reasoning content.
    """

    start_token = "<think>"  # Not generated by model, but used for logic
    end_token = "</think>"

    def extract_reasoning(self, model_output: str, request=None) -> tuple[str | None, str | None]:
        if self.end_token not in model_output:
            return None, model_output
        # Everything before end token is reasoning (even without start token)
        parts = model_output.split(self.end_token, 1)
        reasoning = parts[0].replace(self.start_token, "").strip()
        content = parts[1].strip() if len(parts) > 1 else None
        return reasoning or None, content

    def extract_reasoning_streaming(
        self,
        previous_text: str,
        current_text: str,
        delta_text: str,
        previous_token_ids: Sequence[int],
        current_token_ids: Sequence[int],
        delta_token_ids: Sequence[int],
        request=None,
    ) -> DeltaMessage | None:
        if not delta_text:
            return None

        has_end_in_prev = self.end_token in previous_text
        has_end_in_delta = self.end_token in delta_text

        if has_end_in_prev:
            return DeltaMessage(content=delta_text)

        if has_end_in_delta:
            parts = delta_text.split(self.end_token, 1)
            reasoning_part = parts[0].replace(self.start_token, "")
            content_part = parts[1] if len(parts) > 1 else None
            return DeltaMessage(
                reasoning_content=reasoning_part if reasoning_part else None,
                content=content_part if content_part else None,
            )

        # Still accumulating reasoning (no end token yet)
        cleaned = delta_text.replace(self.start_token, "")
        return DeltaMessage(reasoning_content=cleaned) if cleaned else None


@ReasoningParserManager.register_module(["minimax_m2_append_think"])
class MiniMaxM2AppendThinkReasoningParser(BaseThinkingReasoningParser):
    """Reasoning parser that synthetically prepends <think> to model output.

    Some MiniMax configurations don't generate the start token.
    This parser adds it before parsing.
    """

    start_token = "<think>"
    end_token = "</think>"

    def extract_reasoning(self, model_output: str, request=None) -> tuple[str | None, str | None]:
        if self.start_token not in model_output:
            model_output = self.start_token + model_output
        return super().extract_reasoning(model_output, request)
