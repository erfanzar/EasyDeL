#!/usr/bin/env python3
"""Simple example of eSurge with built-in monitoring."""

import asyncio
import time


def basic_monitoring_example():
    """Basic monitoring example with eSurge."""
    print("ğŸš€ eSurge Simple Monitoring Example")
    print("=" * 40)

    # Initialize eSurge engine
    print("ğŸ¤– Initializing eSurge engine...")

    # NOTE: Replace with your actual model
    # For this example, we'll show the API without loading a real model
    """
    engine = eSurge(
        model="microsoft/DialoGPT-medium",
        max_model_len=1024,
        max_num_seqs=8,
    )
    """

    # Simulated engine for demo purposes
    class MockeSurge:
        def start_monitoring(self, **kwargs):
            print("ğŸš€ Starting eSurge monitoring services...")
            print("ğŸ“Š Metrics collection initialized")
            print("ğŸ“ˆ Prometheus metrics: http://localhost:8000/metrics")
            print("ğŸŒ Web dashboard: http://localhost:8080")
            print("ğŸ©º Health check: http://localhost:8080/health")
            print("\nâœ… Monitoring services started successfully!")
            print("ğŸ“Š Metrics will be automatically collected during inference")
            print("ğŸŒ Open http://localhost:8080 to view real-time metrics")
            return {
                "dashboard": "http://localhost:8080",
                "prometheus": "http://localhost:8000/metrics",
                "health": "http://localhost:8080/health",
                "api": "http://localhost:8080/api/metrics",
            }

        def get_metrics_summary(self):
            return {
                "requests_per_second": 2.5,
                "average_latency": 0.15,
                "average_ttft": 0.03,
                "average_throughput": 45.2,
                "total_completed": 10,
                "total_failed": 0,
                "total_tokens": 452,
                "active_requests": 0,
                "queue_size": 0,
                "running_requests": 0,
            }

        def stop_monitoring(self):
            print("ğŸ›‘ Stopping eSurge monitoring services...")
            print("ğŸ“ˆ Prometheus server stopped")
            print("ğŸŒ Dashboard server will stop with process")
            print("âœ… Monitoring services stopped")

        @property
        def monitoring_active(self):
            return True

    engine = MockeSurge()

    print("âœ… eSurge engine initialized")
    print()

    # Start monitoring with simple one-liner
    print("ğŸ“Š Starting monitoring with default settings...")
    urls = engine.start_monitoring()

    print("\nğŸ“ Monitoring URLs:")
    for service, url in urls.items():
        print(f"   â€¢ {service.title()}: {url}")

    print("\nğŸ”„ Simulating some inference work...")

    # Simulate some work
    time.sleep(2)

    # Check monitoring status
    print(f"\nğŸ“Š Monitoring active: {engine.monitoring_active}")

    # Get metrics summary
    metrics = engine.get_metrics_summary()
    print("\nğŸ“ˆ Current metrics summary:")
    for key, value in metrics.items():
        if isinstance(value, float):
            print(f"   â€¢ {key}: {value:.2f}")
        else:
            print(f"   â€¢ {key}: {value}")

    print("\nâ³ Monitoring services running... Press Ctrl+C to stop")

    try:
        # Keep running to let user see the dashboard
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Stopping services...")
        engine.stop_monitoring()


def advanced_monitoring_example():
    """Advanced monitoring example with custom settings."""
    print("ğŸš€ eSurge Advanced Monitoring Example")
    print("=" * 45)

    # NOTE: Replace with your actual model initialization
    """
    engine = eSurge(
        model="your-model-name",
        max_model_len=2048,
        max_num_seqs=16,
    )
    """

    class MockeSurge:
        def start_monitoring(self, **kwargs):
            print("ğŸš€ Starting eSurge monitoring services...")

            # Show the configured options
            print(f"ğŸ“Š Dashboard port: {kwargs.get('dashboard_port', 8080)}")
            print(f"ğŸ“ˆ Prometheus port: {kwargs.get('prometheus_port', 8000)}")
            print(f"ğŸŒ Host: {kwargs.get('dashboard_host', 'localhost')}")
            print(f"ğŸ“ Log file: {kwargs.get('log_file', 'None')}")
            print(f"â±ï¸ Log interval: {kwargs.get('log_interval', 10.0)}s")
            print(f"ğŸ“Š Enable Prometheus: {kwargs.get('enable_prometheus', True)}")
            print(f"ğŸŒ Enable Dashboard: {kwargs.get('enable_dashboard', True)}")
            print(f"ğŸ–¥ï¸ Enable Console: {kwargs.get('enable_console', False)}")

            host = kwargs.get("dashboard_host", "localhost")
            dash_port = kwargs.get("dashboard_port", 8080)
            prom_port = kwargs.get("prometheus_port", 8000)
            return {
                "dashboard": f"http://{host}:{dash_port}",
                "prometheus": f"http://{host}:{prom_port}/metrics",
                "health": f"http://{host}:{dash_port}/health",
            }

        def stop_monitoring(self):
            print("ğŸ›‘ Monitoring stopped")

    engine = MockeSurge()

    print("ğŸ”§ Starting monitoring with custom configuration...")

    # Advanced monitoring configuration
    urls = engine.start_monitoring(
        dashboard_port=8090,  # Custom dashboard port
        prometheus_port=8010,  # Custom Prometheus port
        dashboard_host="0.0.0.0",  # Listen on all interfaces
        enable_prometheus=True,  # Enable Prometheus metrics
        enable_dashboard=True,  # Enable web dashboard
        enable_console=False,  # Disable console monitor
        log_file="my_esurge_metrics.log",  # Custom log file
        log_interval=5.0,  # Log every 5 seconds
        history_size=2000,  # Keep more history
        enable_detailed_logging=True,  # Detailed logs
    )

    print("\nğŸ“ Custom monitoring URLs:")
    for service, url in urls.items():
        print(f"   â€¢ {service.title()}: {url}")

    print("\nâœ… Advanced monitoring configuration complete!")
    print("ğŸ”§ Try different combinations of settings for your needs")

    # Stop monitoring
    engine.stop_monitoring()


async def production_monitoring_example():
    """Production-ready monitoring example."""
    print("ğŸ­ eSurge Production Monitoring Example")
    print("=" * 45)

    # NOTE: This would be your actual production setup
    """
    engine = eSurge(
        model="your-production-model",
        max_model_len=4096,
        max_num_seqs=32,
        dtype=jnp.float16,  # Memory efficient
    )
    """

    class MockeSurge:
        def __init__(self):
            self._monitoring_active = False

        def start_monitoring(self, **kwargs):
            self._monitoring_active = True
            return {"dashboard": "http://localhost:8080", "prometheus": "http://localhost:8000/metrics"}

        def generate(self, prompts, sampling_params=None):
            # Simulate generation
            await asyncio.sleep(0.1)
            return [f"Generated response for: {prompt[:20]}..." for prompt in prompts]

        def get_metrics_summary(self):
            return {
                "requests_per_second": 15.3,
                "average_latency": 0.08,
                "average_throughput": 234.5,
                "total_completed": 1523,
                "total_failed": 3,
            }

        @property
        def monitoring_active(self):
            return self._monitoring_active

        def stop_monitoring(self):
            self._monitoring_active = False

    engine = MockeSurge()

    print("ğŸš€ Production monitoring setup...")

    # Production monitoring configuration
    urls = engine.start_monitoring(
        dashboard_port=8080,
        prometheus_port=8000,
        dashboard_host="0.0.0.0",  # Accept external connections
        enable_prometheus=True,  # Essential for production
        enable_dashboard=True,  # Web monitoring
        enable_console=False,  # No console in production
        log_file="production_metrics.log",  # Persistent logging
        log_interval=30.0,  # Less frequent logging
        history_size=5000,  # More history for analysis
        enable_detailed_logging=False,  # Reduce log volume
    )

    print("âœ… Production monitoring started")
    print(f"ğŸ“Š Metrics: {urls['prometheus']}")
    print(f"ğŸŒ Dashboard: {urls['dashboard']}")

    # Simulate production workload
    print("\nğŸ”„ Simulating production workload...")

    # Example prompts for testing (not used in simulation)
    # test_prompts = [
    #     "What is machine learning?",
    #     "Explain quantum computing",
    #     "How do neural networks work?",
    #     "What is artificial intelligence?",
    # ]
    # sampling_params = SamplingParams(temperature=0.7, max_tokens=100)

    for i in range(3):
        print(f"ğŸ”„ Processing batch {i+1}/3...")

        # This would be real inference in production
        # results = engine.generate(test_prompts, sampling_params)
        await asyncio.sleep(0.5)  # Simulate work

        # Check metrics
        if engine.monitoring_active:
            metrics = engine.get_metrics_summary()
            print(
                f"   ğŸ“Š RPS: {metrics['requests_per_second']:.1f}, "
                f"Throughput: {metrics['average_throughput']:.1f} tok/s"
            )

    print("\nâœ… Production workload simulation complete")
    print(f"ğŸ“ˆ Check {urls['dashboard']} for detailed metrics")

    engine.stop_monitoring()


def main():
    """Main example selector."""
    print("ğŸš€ eSurge Monitoring Examples")
    print("=" * 35)
    print("Choose an example:")
    print("1. ğŸ“Š Basic monitoring (simple setup)")
    print("2. ğŸ”§ Advanced monitoring (custom config)")
    print("3. ğŸ­ Production monitoring (async example)")
    print("4. âŒ Exit")

    choice = input("\nEnter choice (1-4): ").strip()

    if choice == "1":
        basic_monitoring_example()
    elif choice == "2":
        advanced_monitoring_example()
    elif choice == "3":
        asyncio.run(production_monitoring_example())
    elif choice == "4":
        print("ğŸ‘‹ Goodbye!")
    else:
        print("âŒ Invalid choice")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ›‘ Example interrupted")
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback

        traceback.print_exc()
